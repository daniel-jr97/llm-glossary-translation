{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f39f746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook demonstrates a multi-model translation pipeline using glossary term retrieval and LLM prompting.  \\nIt compares translation quality *with vs. without* retrieval across multiple models (OpenAI GPT-4o-mini, Groq Llama-3.1-8B, and Groq Llama-3.3-70B).\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Translation Pipeline with Glossary-Based Retrieval  \n",
    "\"\"\"\n",
    "This notebook demonstrates a multi-model translation pipeline using glossary term retrieval and LLM prompting.  \n",
    "It compares translation quality *with vs. without* retrieval across multiple models (OpenAI GPT-4o-mini, Groq Llama-3.1-8B, and Groq Llama-3.3-70B).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3901922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in e:\\data\\translation-pipeline\\.venv\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "BASE: e:\\Data\\translation-pipeline\n",
      "DATA: e:\\Data\\translation-pipeline\\data\n",
      "SRC: e:\\Data\\translation-pipeline\\src\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "import os, sys, time, json, hashlib, random\n",
    "import pandas as pd, numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import RateLimitError, APIError\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "\n",
    "# Load .env\n",
    "base = os.getcwd()\n",
    "if os.path.basename(base).lower() == \"notebooks\":\n",
    "    base = os.path.dirname(base)\n",
    "env_path = os.path.join(base, \".env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Project paths\n",
    "BASE = os.getcwd()\n",
    "if os.path.basename(BASE).lower() == \"notebooks\":\n",
    "    BASE = os.path.dirname(BASE)\n",
    "DATA = os.path.join(BASE, \"data\")\n",
    "SRC  = os.path.join(BASE, \"src\")\n",
    "if SRC not in sys.path:\n",
    "    sys.path.append(SRC)\n",
    "\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"DATA:\", DATA)\n",
    "print(\"SRC:\", SRC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00ca83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval import build_glossary_corpus, best_k_terms, select_constraints\n",
    "from prompting import make_prompt, restore_spans\n",
    "from evaluation import term_adherence, basic_metrics\n",
    "from models import generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c4701a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glossary rows: 9\n",
      "Sample rows: 30\n",
      "Prepared corpora: ['fr', 'it', 'ja']\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "glossary = pd.read_csv(os.path.join(DATA, \"glossary.csv\"))\n",
    "samples = pd.read_csv(os.path.join(DATA, \"samples_en.csv\"))\n",
    "print(f\"Glossary rows: {len(glossary)}\")\n",
    "print(f\"Sample rows: {len(samples)}\")\n",
    "\n",
    "corpora = {t: build_glossary_corpus(glossary, t) for t in [\"fr\", \"it\", \"ja\"]}\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "lang_label_map = {\"fr\": \"French\", \"it\": \"Italian\", \"ja\": \"Japanese\"}\n",
    "print(\"Prepared corpora:\", list(corpora.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df387ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator with cache, budget guard, and multi-model routing via src/models.py\n",
    "\n",
    "import os, json, hashlib, time, random\n",
    "import tiktoken\n",
    "from openai import RateLimitError, APIError\n",
    "from models import generate  # router\n",
    "\n",
    "# Configure costs and budget (adjust if you track per-model pricing)\n",
    "INPUT_COST_PER_M  = globals().get(\"INPUT_COST_PER_M\", 0.15)   # $ / 1M input tokens\n",
    "OUTPUT_COST_PER_M = globals().get(\"OUTPUT_COST_PER_M\", 0.60)  # $ / 1M output tokens\n",
    "BUDGET_DOLLARS    = globals().get(\"BUDGET_DOLLARS\", 5.00)\n",
    "\n",
    "# Tokenizer and spending state\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "spent_dollars = globals().get(\"spent_dollars\", 0.0)\n",
    "\n",
    "# On-disk cache (shared across runs)\n",
    "CACHE_PATH = os.path.join(DATA, \"cache.jsonl\")\n",
    "_cache = globals().get(\"_cache\", {})\n",
    "\n",
    "def _load_cache():\n",
    "    if os.path.exists(CACHE_PATH) and not _cache:\n",
    "        with open(CACHE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    rec = json.loads(line)\n",
    "                    _cache[rec[\"key\"]] = rec\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "def _save_cache_item(key, value):\n",
    "    with open(CACHE_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\"key\": key, **value}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _cache_key(source, tgt_lang_label, constraints, model_name):\n",
    "    payload = {\n",
    "        \"src\": source,\n",
    "        \"tgt\": tgt_lang_label,\n",
    "        \"constraints\": constraints,\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "    s = json.dumps(payload, sort_keys=True, ensure_ascii=False)\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _estimate_cost_usd(prompt_text: str, completion_text: str = \"\") -> float:\n",
    "    in_tok = len(enc.encode(prompt_text))\n",
    "    out_tok = len(enc.encode(completion_text)) if completion_text else 0\n",
    "    return (in_tok/1_000_000.0)*INPUT_COST_PER_M + (out_tok/1_000_000.0)*OUTPUT_COST_PER_M\n",
    "\n",
    "def translate_llm_safe(source: str, tgt_lang_label: str, constraints, model_name: str,\n",
    "                       temperature: float = 0.2, max_retries: int = 5, base_sleep: float = 0.8):\n",
    "    \"\"\"\n",
    "    Returns (hypothesis, latency_seconds).\n",
    "    model_name must be present in models.MODEL_ROUTING (e.g., 'gpt-4o-mini', 'llama3-8b', 'llama3-70b').\n",
    "    \"\"\"\n",
    "    global spent_dollars\n",
    "    _load_cache()\n",
    "\n",
    "    prompt, spans = make_prompt(source, tgt_lang_label, constraints)\n",
    "    key = _cache_key(source, tgt_lang_label, constraints, model_name)\n",
    "\n",
    "    # Cache hit\n",
    "    if key in _cache:\n",
    "        rec = _cache[key]\n",
    "        hyp = restore_spans(rec[\"hyp\"], spans)\n",
    "        return hyp, rec[\"latency_s\"]\n",
    "\n",
    "    # Budget guard on input estimate\n",
    "    est_in_cost = _estimate_cost_usd(prompt, \"\")\n",
    "    if spent_dollars + est_in_cost > BUDGET_DOLLARS:\n",
    "        raise RuntimeError(f\"Budget guard tripped at ${spent_dollars:.2f}/${BUDGET_DOLLARS:.2f}. Reduce rows or raise budget.\")\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            hyp_raw = generate(model_name, messages=[{\"role\": \"user\", \"content\": prompt}], temperature=temperature)\n",
    "            hyp = restore_spans(hyp_raw.strip(), spans)\n",
    "            latency = time.time() - start\n",
    "\n",
    "            # Account for input + output\n",
    "            spent_dollars += _estimate_cost_usd(prompt, hyp)\n",
    "\n",
    "            # Persist\n",
    "            value = {\"hyp\": hyp, \"latency_s\": latency}\n",
    "            _cache[key] = value\n",
    "            _save_cache_item(key, value)\n",
    "\n",
    "            time.sleep(0.2)  # small throttle\n",
    "            return hyp, latency\n",
    "\n",
    "        except (RateLimitError, APIError):\n",
    "            attempt += 1\n",
    "            if attempt > max_retries:\n",
    "                raise\n",
    "            time.sleep(base_sleep * (2 ** (attempt - 1)) + random.uniform(0, 0.4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77ecdcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: gpt-4o-mini\n",
      "SOURCE: Enter your email address to continue.\n",
      "TARGET: French\n",
      "\n",
      "WITH retrieval:\n",
      "Entrez votre adresse e-mail pour continuer.\n",
      "(latency: 1.21s)\n",
      "\n",
      "WITHOUT retrieval:\n",
      "Entrez votre adresse e-mail pour continuer.\n",
      "(latency: 0.71s)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: run a single sentence through one model to verify everything\n",
    "row = samples.iloc[0]  # change index to try other examples\n",
    "src = row[\"src\"]\n",
    "tgt = row[\"pair\"].split(\"-\")[-1]      # 'fr', 'it', or 'ja'\n",
    "tgt_label = lang_label_map[tgt]\n",
    "\n",
    "# Retrieval\n",
    "docs = corpora[tgt]\n",
    "idxs = best_k_terms(src, docs, embeddings=embedder, k=3)\n",
    "cons = select_constraints(glossary, idxs, tgt)\n",
    "\n",
    "# Model to sanity-test\n",
    "model_name = \"gpt-4o-mini\"  # or \"llama3-8b\" / \"llama3-70b\"\n",
    "\n",
    "hyp_with,  lat_with = translate_llm_safe(src, tgt_label, cons,            model_name=model_name)\n",
    "hyp_without, lat_wo = translate_llm_safe(src, tgt_label, constraints=[],  model_name=model_name)\n",
    "\n",
    "print(\"MODEL:\", model_name)\n",
    "print(\"SOURCE:\", src)\n",
    "print(\"TARGET:\", tgt_label)\n",
    "print(\"\\nWITH retrieval:\")\n",
    "print(hyp_with)\n",
    "print(f\"(latency: {lat_with:.2f}s)\")\n",
    "print(\"\\nWITHOUT retrieval:\")\n",
    "print(hyp_without)\n",
    "print(f\"(latency: {lat_wo:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed1d138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model: gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:43<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\Data\\translation-pipeline\\data\\results_gpt-4o-mini_n50.csv\n",
      "\n",
      "Running model: llama3-8b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:26<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\Data\\translation-pipeline\\data\\results_llama3-8b_n50.csv\n",
      "\n",
      "Running model: llama3-70b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:22<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\Data\\translation-pipeline\\data\\results_llama3-70b_n50.csv\n",
      "Saved combined: e:\\Data\\translation-pipeline\\data\\results_all_models_n50.csv\n",
      "\n",
      "Mean term adherence by model (n=50 each):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_acc_with</th>\n",
       "      <th>term_acc_without</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3-70b</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3-8b</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_acc_with  term_acc_without\n",
       "model                                       \n",
       "gpt-4o-mini           0.36              0.25\n",
       "llama3-70b            0.31              0.21\n",
       "llama3-8b             0.31              0.16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean term adherence by model and language (n=50 total):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_acc_with</th>\n",
       "      <th>term_acc_without</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gpt-4o-mini</th>\n",
       "      <th>en-fr</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-it</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-ja</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama3-70b</th>\n",
       "      <th>en-fr</th>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-it</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-ja</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama3-8b</th>\n",
       "      <th>en-fr</th>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-it</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-ja</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   term_acc_with  term_acc_without\n",
       "model       pair                                  \n",
       "gpt-4o-mini en-fr       0.421053          0.342105\n",
       "            en-it       0.281250          0.156250\n",
       "            en-ja       0.366667          0.233333\n",
       "llama3-70b  en-fr       0.342105          0.315789\n",
       "            en-it       0.218750          0.156250\n",
       "            en-ja       0.366667          0.133333\n",
       "llama3-8b   en-fr       0.368421          0.210526\n",
       "            en-it       0.281250          0.156250\n",
       "            en-ja       0.266667          0.100000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Batch comparison over 50 rows: gpt-4o-mini (OpenAI), llama3-8b (Groq), llama3-70b (Groq)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODELS = [\"gpt-4o-mini\", \"llama3-8b\", \"llama3-70b\"]\n",
    "\n",
    "subset = samples.head(50)   # ensure we process 50 rows\n",
    "all_records = []\n",
    "\n",
    "for model_name in MODELS:\n",
    "    print(f\"\\nRunning model: {model_name}\")\n",
    "    model_records = []\n",
    "\n",
    "    for _, row in tqdm(subset.iterrows(), total=len(subset)):\n",
    "        src = row[\"src\"]\n",
    "        tgt = row[\"pair\"].split(\"-\")[-1]\n",
    "        tgt_label = lang_label_map[tgt]\n",
    "\n",
    "        # retrieval\n",
    "        docs = corpora[tgt]\n",
    "        idxs = best_k_terms(src, docs, embeddings=embedder, k=2)\n",
    "        cons = select_constraints(glossary, idxs, tgt)\n",
    "\n",
    "        # with and without retrieval\n",
    "        hyp_with, lat_with = translate_llm_safe(src, tgt_label, cons,            model_name=model_name)\n",
    "        hyp_wo,   lat_wo   = translate_llm_safe(src, tgt_label, constraints=[],  model_name=model_name)\n",
    "\n",
    "        ta_with = term_adherence(hyp_with, cons)\n",
    "        ta_wo   = term_adherence(hyp_wo,   cons)\n",
    "\n",
    "        model_records.append({\n",
    "            \"model\": model_name,\n",
    "            \"id\": row[\"id\"],\n",
    "            \"pair\": row[\"pair\"],\n",
    "            \"source\": src,\n",
    "            \"hyp_with\": hyp_with,\n",
    "            \"hyp_without\": hyp_wo,\n",
    "            \"term_acc_with\": ta_with,\n",
    "            \"term_acc_without\": ta_wo,\n",
    "            \"lat_with_s\": lat_with,\n",
    "            \"lat_without_s\": lat_wo,\n",
    "        })\n",
    "\n",
    "    df_m = pd.DataFrame(model_records)\n",
    "    out_csv = os.path.join(DATA, f\"results_{model_name.replace('/', '_')}_n50.csv\")\n",
    "    df_m.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_csv)\n",
    "\n",
    "    all_records.extend(model_records)\n",
    "\n",
    "# Combined results for all models\n",
    "results_all = pd.DataFrame(all_records)\n",
    "combined_csv = os.path.join(DATA, \"results_all_models_n50.csv\")\n",
    "results_all.to_csv(combined_csv, index=False)\n",
    "print(\"Saved combined:\", combined_csv)\n",
    "\n",
    "# Quick summaries\n",
    "print(\"\\nMean term adherence by model (n=50 each):\")\n",
    "display(results_all.groupby(\"model\")[[\"term_acc_with\",\"term_acc_without\"]].mean())\n",
    "\n",
    "print(\"\\nMean term adherence by model and language (n=50 total):\")\n",
    "display(results_all.groupby([\"model\",\"pair\"])[[\"term_acc_with\",\"term_acc_without\"]].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a53af01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-model HTML: e:\\Data\\translation-pipeline\\data\\side_by_side_gpt-4o-mini_n50_20251014_002631.html\n",
      "Saved per-model HTML: e:\\Data\\translation-pipeline\\data\\side_by_side_llama3-8b_n50_20251014_002631.html\n",
      "Saved per-model HTML: e:\\Data\\translation-pipeline\\data\\side_by_side_llama3-70b_n50_20251014_002631.html\n",
      "Saved combined HTML: e:\\Data\\translation-pipeline\\data\\side_by_side_all_models_n50_20251014_002631.html\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ts = time.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 3A) Per-model HTML reports\n",
    "for m in MODELS:\n",
    "    dfm = results_all[results_all[\"model\"] == m].copy()\n",
    "    html_path = os.path.join(DATA, f\"side_by_side_{m.replace('/','_')}_n50_{ts}.html\")\n",
    "\n",
    "    html_header = \"\"\"\n",
    "    <html><head>\n",
    "    <style>\n",
    "    body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "    table { border-collapse: collapse; width: 100%; }\n",
    "    th, td { border: 1px solid #ccc; padding: 8px; vertical-align: top; }\n",
    "    th { background-color: #f2f2f2; }\n",
    "    </style></head><body>\n",
    "    \"\"\"\n",
    "    html_title = f\"<h2>Translation Comparison (With vs Without Retrieval) — {m}</h2>\"\n",
    "    table_head = \"<table><tr><th>ID</th><th>Language Pair</th><th>Source</th><th>With Retrieval</th><th>Without Retrieval</th></tr>\"\n",
    "    rows = []\n",
    "    for _, r in dfm.iterrows():\n",
    "        rows.append(\n",
    "            f\"<tr><td>{r.id}</td><td>{r.pair}</td><td>{r.source}</td><td>{r.hyp_with}</td><td>{r.hyp_without}</td></tr>\"\n",
    "        )\n",
    "    html_footer = \"</table></body></html>\"\n",
    "\n",
    "    with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_header + html_title + table_head + \"\".join(rows) + html_footer)\n",
    "\n",
    "    print(\"Saved per-model HTML:\", html_path)\n",
    "\n",
    "# 3B) Combined HTML across all models\n",
    "html_path_all = os.path.join(DATA, f\"side_by_side_all_models_n50_{ts}.html\")\n",
    "\n",
    "html_header = \"\"\"\n",
    "<html><head>\n",
    "<style>\n",
    "body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "table { border-collapse: collapse; width: 100%; }\n",
    "th, td { border: 1px solid #ccc; padding: 8px; vertical-align: top; }\n",
    "th { background-color: #f2f2f2; }\n",
    "</style></head><body>\n",
    "\"\"\"\n",
    "html_title = \"<h2>Translation Comparison (With vs Without Retrieval) — All Models</h2>\"\n",
    "table_head = \"<table><tr><th>Model</th><th>ID</th><th>Language Pair</th><th>Source</th><th>With Retrieval</th><th>Without Retrieval</th></tr>\"\n",
    "rows = []\n",
    "for _, r in results_all.iterrows():\n",
    "    rows.append(\n",
    "        f\"<tr><td>{r.model}</td><td>{r.id}</td><td>{r.pair}</td><td>{r.source}</td><td>{r.hyp_with}</td><td>{r.hyp_without}</td></tr>\"\n",
    "    )\n",
    "html_footer = \"</table></body></html>\"\n",
    "\n",
    "with open(html_path_all, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_header + html_title + table_head + \"\".join(rows) + html_footer)\n",
    "\n",
    "print(\"Saved combined HTML:\", html_path_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b6143c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary: e:\\Data\\translation-pipeline\\data\\summary_by_model_n50_20251014_002631.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>term_acc_with</th>\n",
       "      <th>term_acc_without</th>\n",
       "      <th>lat_with_s</th>\n",
       "      <th>lat_without_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.376952</td>\n",
       "      <td>1.211499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama3-70b</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.879641</td>\n",
       "      <td>1.868458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.524870</td>\n",
       "      <td>2.066580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  term_acc_with  term_acc_without  lat_with_s  lat_without_s\n",
       "0  gpt-4o-mini           0.36              0.25    1.376952       1.211499\n",
       "1   llama3-70b           0.31              0.21    1.879641       1.868458\n",
       "2    llama3-8b           0.31              0.16    1.524870       2.066580"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary by model and language: e:\\Data\\translation-pipeline\\data\\summary_by_model_language_n50_20251014_002631.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pair</th>\n",
       "      <th>term_acc_with</th>\n",
       "      <th>term_acc_without</th>\n",
       "      <th>lat_with_s</th>\n",
       "      <th>lat_without_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>en-fr</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>1.264941</td>\n",
       "      <td>1.845590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>en-it</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>1.180823</td>\n",
       "      <td>0.758619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>en-ja</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.728038</td>\n",
       "      <td>0.891389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3-70b</td>\n",
       "      <td>en-fr</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1.263774</td>\n",
       "      <td>1.399020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3-70b</td>\n",
       "      <td>en-it</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>1.481054</td>\n",
       "      <td>2.816360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3-70b</td>\n",
       "      <td>en-ja</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>3.084898</td>\n",
       "      <td>1.451985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>en-fr</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>1.445053</td>\n",
       "      <td>1.986498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>en-it</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>1.621024</td>\n",
       "      <td>2.082973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>en-ja</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.523408</td>\n",
       "      <td>2.150531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model   pair  term_acc_with  term_acc_without  lat_with_s  \\\n",
       "0  gpt-4o-mini  en-fr       0.421053          0.342105    1.264941   \n",
       "1  gpt-4o-mini  en-it       0.281250          0.156250    1.180823   \n",
       "2  gpt-4o-mini  en-ja       0.366667          0.233333    1.728038   \n",
       "3   llama3-70b  en-fr       0.342105          0.315789    1.263774   \n",
       "4   llama3-70b  en-it       0.218750          0.156250    1.481054   \n",
       "5   llama3-70b  en-ja       0.366667          0.133333    3.084898   \n",
       "6    llama3-8b  en-fr       0.368421          0.210526    1.445053   \n",
       "7    llama3-8b  en-it       0.281250          0.156250    1.621024   \n",
       "8    llama3-8b  en-ja       0.266667          0.100000    1.523408   \n",
       "\n",
       "   lat_without_s  \n",
       "0       1.845590  \n",
       "1       0.758619  \n",
       "2       0.891389  \n",
       "3       1.399020  \n",
       "4       2.816360  \n",
       "5       1.451985  \n",
       "6       1.986498  \n",
       "7       2.082973  \n",
       "8       2.150531  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Per-model summary\n",
    "summary_model = results_all.groupby(\"model\")[[\"term_acc_with\",\"term_acc_without\",\"lat_with_s\",\"lat_without_s\"]].mean().reset_index()\n",
    "summary_csv = os.path.join(DATA, f\"summary_by_model_n50_{ts}.csv\")\n",
    "summary_model.to_csv(summary_csv, index=False)\n",
    "print(\"Saved summary:\", summary_csv)\n",
    "display(summary_model)\n",
    "\n",
    "# Per-model, per-language summary\n",
    "summary_model_lang = results_all.groupby([\"model\",\"pair\"])[[\"term_acc_with\",\"term_acc_without\",\"lat_with_s\",\"lat_without_s\"]].mean().reset_index()\n",
    "summary_ml_csv = os.path.join(DATA, f\"summary_by_model_language_n50_{ts}.csv\")\n",
    "summary_model_lang.to_csv(summary_ml_csv, index=False)\n",
    "print(\"Saved summary by model and language:\", summary_ml_csv)\n",
    "display(summary_model_lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

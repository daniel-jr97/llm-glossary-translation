{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ca83ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: e:\\Data\\translation-pipeline\n",
      "DATA: e:\\Data\\translation-pipeline\\data\n",
      "SRC: e:\\Data\\translation-pipeline\\src\n",
      "SRC files: ['evaluation.py', 'prompting.py', 'retrieval.py']\n"
     ]
    }
   ],
   "source": [
    "# ---- Setup: imports, API client, paths, and our src modules ----\n",
    "import os, sys, time, pandas as pd, numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "# Use your environment variable (set in the VS Code terminal)\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Detect project root whether the notebook is in /notebooks or not\n",
    "BASE = os.getcwd()\n",
    "if os.path.basename(BASE).lower() == \"notebooks\":\n",
    "    BASE = os.path.dirname(BASE)\n",
    "\n",
    "DATA = os.path.join(BASE, \"data\")\n",
    "SRC  = os.path.join(BASE, \"src\")\n",
    "\n",
    "if SRC not in sys.path:\n",
    "    sys.path.append(SRC)\n",
    "\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"DATA:\", DATA)\n",
    "print(\"SRC:\", SRC)\n",
    "print(\"SRC files:\", os.listdir(SRC))\n",
    "\n",
    "from retrieval import build_glossary_corpus, best_k_terms, select_constraints\n",
    "from prompting import make_prompt, restore_spans\n",
    "from evaluation import term_adherence, basic_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4701a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Data\\translation-pipeline\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glossary rows: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>domain</th>\n",
       "      <th>definition</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>ja</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPU</td>\n",
       "      <td>noun</td>\n",
       "      <td>tech</td>\n",
       "      <td>Graphics processing unit for parallel computat...</td>\n",
       "      <td>GPU</td>\n",
       "      <td>processeur graphique</td>\n",
       "      <td>GPU</td>\n",
       "      <td>ＧＰＵ</td>\n",
       "      <td>Keep as acronym; target forms preferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account ID</td>\n",
       "      <td>noun</td>\n",
       "      <td>finance</td>\n",
       "      <td>Unique identifier for user accounts</td>\n",
       "      <td>account ID</td>\n",
       "      <td>ID de compte</td>\n",
       "      <td>ID account</td>\n",
       "      <td>アカウントID</td>\n",
       "      <td>Do not translate \"ID\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Checkout</td>\n",
       "      <td>verb</td>\n",
       "      <td>commerce</td>\n",
       "      <td>The process of completing a purchase</td>\n",
       "      <td>checkout</td>\n",
       "      <td>paiement</td>\n",
       "      <td>cassa</td>\n",
       "      <td>チェックアウト</td>\n",
       "      <td>May be noun/verb; prefer payment flow sense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term part_of_speech    domain  \\\n",
       "0         GPU           noun      tech   \n",
       "1  Account ID           noun   finance   \n",
       "2    Checkout           verb  commerce   \n",
       "\n",
       "                                          definition          en  \\\n",
       "0  Graphics processing unit for parallel computat...         GPU   \n",
       "1                Unique identifier for user accounts  account ID   \n",
       "2               The process of completing a purchase    checkout   \n",
       "\n",
       "                     fr          it       ja  \\\n",
       "0  processeur graphique         GPU      ＧＰＵ   \n",
       "1          ID de compte  ID account  アカウントID   \n",
       "2              paiement       cassa  チェックアウト   \n",
       "\n",
       "                                         notes  \n",
       "0      Keep as acronym; target forms preferred  \n",
       "1                        Do not translate \"ID\"  \n",
       "2  May be noun/verb; prefer payment flow sense  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>pair</th>\n",
       "      <th>has_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Enter your email address to continue.</td>\n",
       "      <td>en-fr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Free shipping on orders over $50 at checkout.</td>\n",
       "      <td>en-it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Enable two-factor authentication (2FA) in Sett...</td>\n",
       "      <td>en-ja</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Your refund has been issued to the original pa...</td>\n",
       "      <td>en-it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copy the Account ID and share it with support.</td>\n",
       "      <td>en-fr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                src   pair  has_html\n",
       "0   1              Enter your email address to continue.  en-fr         0\n",
       "1   2      Free shipping on orders over $50 at checkout.  en-it         0\n",
       "2   3  Enable two-factor authentication (2FA) in Sett...  en-ja         0\n",
       "3   4  Your refund has been issued to the original pa...  en-it         0\n",
       "4   5     Copy the Account ID and share it with support.  en-fr         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared corpora for: ['fr', 'it', 'ja']\n"
     ]
    }
   ],
   "source": [
    "# ---- Load data & prepare retrieval ----\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1) Load CSVs\n",
    "glossary = pd.read_csv(os.path.join(DATA, \"glossary.csv\"))\n",
    "samples  = pd.read_csv(os.path.join(DATA, \"samples_en.csv\"))\n",
    "\n",
    "print(\"Glossary rows:\", len(glossary))\n",
    "display(glossary.head(3))\n",
    "print(\"Sample rows:\", len(samples))\n",
    "display(samples.head(5))\n",
    "\n",
    "# 2) Build per-language \"documents\" from the glossary (text used for retrieval)\n",
    "corpora = {}\n",
    "for tgt in [\"fr\", \"it\", \"ja\"]:\n",
    "    corpora[tgt] = build_glossary_corpus(glossary, tgt)\n",
    "\n",
    "# 3) Create the embedding model (fast & decent quality)\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4) Map short codes to friendly names for prompts\n",
    "lang_label_map = {\"fr\": \"French\", \"it\": \"Italian\", \"ja\": \"Japanese\"}\n",
    "\n",
    "print(\"Prepared corpora for:\", list(corpora.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df387ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Caching + budget guard (paste once) ---\n",
    "import os, json, hashlib, time, random\n",
    "import tiktoken\n",
    "from openai import RateLimitError, APIError\n",
    "\n",
    "# --------- adjust these to your current model prices ---------\n",
    "# Fill with your model's current $/1M tokens (input/output) from your dashboard\n",
    "INPUT_COST_PER_M = 0.15   # dollars per 1M input tokens (example)\n",
    "OUTPUT_COST_PER_M = 0.60  # dollars per 1M output tokens (example)\n",
    "BUDGET_DOLLARS = 5.00     # hard cap for this run\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")  # decent default for OpenAI chat models\n",
    "spent_dollars = 0.0\n",
    "\n",
    "CACHE_PATH = os.path.join(DATA, \"cache.jsonl\")\n",
    "_cache = {}\n",
    "\n",
    "def _load_cache():\n",
    "    if os.path.exists(CACHE_PATH):\n",
    "        with open(CACHE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    rec = json.loads(line)\n",
    "                    _cache[rec[\"key\"]] = rec\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "def _save_cache_item(key, value):\n",
    "    with open(CACHE_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\"key\": key, **value}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _cache_key(source, tgt_lang_label, constraints, model):\n",
    "    s = json.dumps({\n",
    "        \"src\": source,\n",
    "        \"tgt\": tgt_lang_label,\n",
    "        \"constraints\": constraints,\n",
    "        \"model\": model\n",
    "    }, sort_keys=True, ensure_ascii=False)\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _estimate_cost_usd(prompt_text: str, completion_text: str = \"\") -> float:\n",
    "    in_tok = len(enc.encode(prompt_text))\n",
    "    out_tok = len(enc.encode(completion_text)) if completion_text else 0\n",
    "    return (in_tok/1_000_000.0)*INPUT_COST_PER_M + (out_tok/1_000_000.0)*OUTPUT_COST_PER_M\n",
    "\n",
    "# Replaces your previous translate_llm_safe (adds cache + cost guard)\n",
    "def translate_llm_safe(source: str, tgt_lang_label: str, constraints, model=\"gpt-4o-mini\",\n",
    "                       temperature: float = 0.2, max_retries: int = 5, base_sleep: float = 0.8):\n",
    "    global spent_dollars\n",
    "\n",
    "    prompt, spans = make_prompt(source, tgt_lang_label, constraints)\n",
    "    key = _cache_key(source, tgt_lang_label, constraints, model)\n",
    "\n",
    "    # Cache hit?\n",
    "    if key in _cache:\n",
    "        rec = _cache[key]\n",
    "        hyp = restore_spans(rec[\"hyp\"], spans)\n",
    "        return hyp, rec[\"latency_s\"]\n",
    "\n",
    "    # Budget check (input-side prediction)\n",
    "    est_in_cost = _estimate_cost_usd(prompt, \"\")\n",
    "    if spent_dollars + est_in_cost > BUDGET_DOLLARS:\n",
    "        raise RuntimeError(f\"Budget guard tripped at ${spent_dollars:.2f}/${BUDGET_DOLLARS:.2f}. \"\n",
    "                           \"Lower k, reduce rows, or increase budget.\")\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            hyp = resp.choices[0].message.content.strip()\n",
    "            hyp_restored = restore_spans(hyp, spans)\n",
    "            latency = time.time() - start\n",
    "\n",
    "            # Estimate full (input + output) cost for accounting\n",
    "            spent_dollars += _estimate_cost_usd(prompt, hyp)\n",
    "\n",
    "            # Save to cache\n",
    "            value = {\"hyp\": hyp, \"latency_s\": latency}\n",
    "            _cache[key] = value\n",
    "            _save_cache_item(key, value)\n",
    "\n",
    "            time.sleep(0.2)\n",
    "            return hyp_restored, latency\n",
    "\n",
    "        except (RateLimitError, APIError):\n",
    "            attempt += 1\n",
    "            if attempt > max_retries:\n",
    "                raise\n",
    "            time.sleep(base_sleep * (2 ** (attempt - 1)) + random.uniform(0, 0.4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da35b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Translator with light retry/backoff ----\n",
    "import time, random\n",
    "from openai import RateLimitError, APIError\n",
    "\n",
    "def translate_llm_safe(source: str, tgt_lang_label: str, constraints, model=\"gpt-4o-mini\",\n",
    "                       temperature: float = 0.2, max_retries: int = 5, base_sleep: float = 0.8):\n",
    "    prompt, spans = make_prompt(source, tgt_lang_label, constraints)\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            hyp = resp.choices[0].message.content.strip()\n",
    "            hyp = restore_spans(hyp, spans)\n",
    "            latency = time.time() - start\n",
    "            # Tiny pause to avoid bursty calls\n",
    "            time.sleep(0.2)\n",
    "            return hyp, latency\n",
    "        except (RateLimitError, APIError) as e:\n",
    "            attempt += 1\n",
    "            if attempt > max_retries:\n",
    "                raise\n",
    "            sleep_s = base_sleep * (2 ** (attempt - 1)) + random.uniform(0, 0.4)\n",
    "            time.sleep(sleep_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046ad1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: Enter your email address to continue.\n",
      "TARGET: French\n",
      "\n",
      "--- WITH retrieval ---\n",
      "Entrez votre adresse e-mail pour continuer. \n",
      "(latency: 1.01s)\n",
      "\n",
      "--- WITHOUT retrieval ---\n",
      "Entrez votre adresse e-mail pour continuer. \n",
      "(latency: 3.74s)\n"
     ]
    }
   ],
   "source": [
    "# ---- Quick single test (first row) ----\n",
    "row = samples.iloc[0]\n",
    "src = row[\"src\"]\n",
    "tgt = row[\"pair\"].split(\"-\")[-1]          # 'fr', 'it', or 'ja'\n",
    "tgt_label = lang_label_map[tgt]           # 'French', 'Italian', 'Japanese'\n",
    "\n",
    "# Retrieve constraints\n",
    "docs = corpora[tgt]\n",
    "idxs = best_k_terms(src, docs, embeddings=embedder, k=3)\n",
    "cons = select_constraints(glossary, idxs, tgt)\n",
    "\n",
    "# Translate WITH retrieval\n",
    "hyp_with, lat_with = translate_llm_safe(src, tgt_label, cons)\n",
    "\n",
    "# Translate WITHOUT retrieval\n",
    "hyp_wo, lat_wo = translate_llm_safe(src, tgt_label, constraints=[])\n",
    "\n",
    "print(\"SOURCE:\", src)\n",
    "print(\"TARGET:\", tgt_label)\n",
    "print(\"\\n--- WITH retrieval ---\")\n",
    "print(hyp_with, f\"\\n(latency: {lat_with:.2f}s)\")\n",
    "print(\"\\n--- WITHOUT retrieval ---\")\n",
    "print(hyp_wo, f\"\\n(latency: {lat_wo:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Small-chunk batch with budget guard ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "subset = samples.head(30)   # adjust; later do the rest\n",
    "records = []\n",
    "\n",
    "for _, row in tqdm(subset.iterrows(), total=len(subset)):\n",
    "    src = row[\"src\"]\n",
    "    tgt = row[\"pair\"].split(\"-\")[-1]\n",
    "    tgt_label = lang_label_map[tgt]\n",
    "\n",
    "    # Retrieval\n",
    "    docs = corpora[tgt]\n",
    "    idxs = best_k_terms(src, docs, embeddings=embedder, k=3)  # try k=2 if you want shorter prompts\n",
    "    cons = select_constraints(glossary, idxs, tgt)\n",
    "\n",
    "    # WITH retrieval\n",
    "    hyp_with, lat_with = translate_llm_safe(src, tgt_label, cons)\n",
    "\n",
    "    # WITHOUT retrieval\n",
    "    hyp_wo, lat_wo = translate_llm_safe(src, tgt_label, constraints=[])\n",
    "\n",
    "    # Metrics\n",
    "    ta_with = term_adherence(hyp_with, cons)\n",
    "    ta_wo   = term_adherence(hyp_wo, cons)\n",
    "\n",
    "    records.append({\n",
    "        \"id\": row[\"id\"], \"pair\": row[\"pair\"], \"source\": src,\n",
    "        \"hyp_with\": hyp_with, \"hyp_without\": hyp_wo,\n",
    "        \"term_acc_with\": ta_with, \"term_acc_without\": ta_wo,\n",
    "        \"lat_with_s\": lat_with, \"lat_without_s\": lat_wo\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(records)\n",
    "print(f\"Spent (estimated): ${spent_dollars:.2f}\")\n",
    "results.head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
